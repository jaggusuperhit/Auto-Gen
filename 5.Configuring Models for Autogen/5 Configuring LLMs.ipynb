{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring LLMs in AutoGen v0.4+\n",
    "Starting with OpenAIâ€™s GPT-4.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the Chat GPT / OpenAI code here\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "model_client = OpenAIChatCompletionClient(model='gpt-4o', api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('GEMINI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyCtfvtAMQxcf3SLdFs5n6kRLQYSRnpZ4D0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autogen'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Best practice for Gemini models\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magentchat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcontrib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgemini\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GeminiClient\n\u001b[32m      4\u001b[39m model_client = GeminiClient(\n\u001b[32m      5\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-pro\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     api_key=api_key\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m response = model_client.send_request(\n\u001b[32m     10\u001b[39m     messages=[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mWho are you?\u001b[39m\u001b[33m\"\u001b[39m}]\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'autogen'"
     ]
    }
   ],
   "source": [
    "# Best practice for Gemini models\n",
    "from autogen.agentchat.contrib.gemini import GeminiClient\n",
    "\n",
    "model_client = GeminiClient(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "response = model_client.send_request(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Who are you?\"}]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ollama'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UserMessage\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen_ext\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OllamaChatCompletionClient\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Assuming your Ollama server is running locally on port 11434.\u001b[39;00m\n\u001b[32m      5\u001b[39m ollama_model_client = OllamaChatCompletionClient(model=\u001b[33m\"\u001b[39m\u001b[33mllama3.2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Autogen\\Auto-Gen\\myenv\\Lib\\site-packages\\autogen_ext\\models\\ollama\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_ollama_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OllamaChatCompletionClient\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     BaseOllamaClientConfigurationConfigModel,\n\u001b[32m      4\u001b[39m     CreateArgumentsConfigModel,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m __all__ = [\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mOllamaChatCompletionClient\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBaseOllamaClientConfigurationConfigModel\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCreateArgumentsConfigModel\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Autogen\\Auto-Gen\\myenv\\Lib\\site-packages\\autogen_ext\\models\\ollama\\_ollama_client.py:47\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     33\u001b[39m     AssistantMessage,\n\u001b[32m     34\u001b[39m     ChatCompletionClient,\n\u001b[32m   (...)\u001b[39m\u001b[32m     44\u001b[39m     UserMessage,\n\u001b[32m     45\u001b[39m )\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tool, ToolSchema\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AsyncClient, ChatResponse, Message\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m OllamaImage\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tool \u001b[38;5;28;01mas\u001b[39;00m OllamaTool\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'ollama'"
     ]
    }
   ],
   "source": [
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "\n",
    "# Assuming your Ollama server is running locally on port 11434.\n",
    "ollama_model_client = OllamaChatCompletionClient(model=\"llama3.2\")\n",
    "\n",
    "response = await ollama_model_client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(response)\n",
    "await ollama_model_client.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finish_reason='stop' content='The capital of France is Paris.' usage=RequestUsage(prompt_tokens=32, completion_tokens=8) cached=False logprobs=None thought=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name='assistant',\n",
    "    model_client=ollama_model_client,\n",
    "    system_message='You are a helpful assistant',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labrador Retrievers! Here's some interesting information about one of the most popular breeds in the world:\n",
      "\n",
      "**Origin**\n",
      "-----------------\n",
      "\n",
      "The Labrador Retriever originated in Newfoundland, Canada, where they were bred to assist fishermen and retrieve fish. The breed was developed by crossing local dogs with other breeds, including the St. John's Water Dog.\n",
      "\n",
      "**Physical Characteristics**\n",
      "-----------------------------\n",
      "\n",
      "* **Size:** Males: 22.5-24.5 inches (57-62 cm) tall at the shoulder; females: 21.5-23.5 inches (55-60 cm)\n",
      "* **Weight:** 55-80 pounds (25-36 kg)\n",
      "* **Coat:** Short, dense, and smooth\n",
      "* **Color:** Black, yellow, or chocolate\n",
      "\n",
      "**Personality**\n",
      "-----------------\n",
      "\n",
      "Labrador Retrievers are known for their friendly, outgoing, and energetic personalities. They:\n",
      "\n",
      "* Are highly social and love people\n",
      "* Are excellent family dogs and are often used as therapy dogs\n",
      "* Are highly intelligent and trainable\n",
      "* Love to please their owners and enjoy pleasing them with good behavior\n",
      "\n",
      "**Health**\n",
      "-------------\n",
      "\n",
      "Labrador Retrievers are generally a healthy breed, but like all breeds, they can be prone to certain health issues:\n",
      "\n",
      "* Hip dysplasia\n",
      "* Elbow dysplasia\n",
      "* Obesity\n",
      "* Eye problems (e.g., cataracts, progressive retinal atrophy)\n",
      "* Allergies\n",
      "\n",
      "**Grooming**\n",
      "-------------\n",
      "\n",
      "Labrador Retrievers have a short, dense coat that requires minimal grooming. They need to be brushed occasionally to remove loose hair and distribute skin oils.\n",
      "\n",
      "**Exercise Needs**\n",
      "-------------------\n",
      "\n",
      "Labrador Retrievers are high-energy dogs that require regular exercise to stay happy and healthy:\n",
      "\n",
      "* Daily walks (at least 30 minutes)\n",
      "* Playtime (e.g., fetch, running, swimming)\n",
      "* Mental stimulation (e.g., obedience training, puzzle toys)\n",
      "\n",
      "**Fun Facts**\n",
      "----------------\n",
      "\n",
      "* Labradors are one of the most popular breeds in the world, according to the American Kennel Club.\n",
      "* They were originally bred as hunting dogs, but today they're often used as service dogs, therapy dogs, and family pets.\n",
      "* The breed's name comes from their country of origin (Labrador) and their original purpose (retrieving fish).\n",
      "\n",
      "I hope you found this information helpful! Do you have any specific questions about Labrador Retrievers?\n"
     ]
    }
   ],
   "source": [
    "result = await agent.run(task='Find information about Labrador Retriever')\n",
    "print(result.messages[-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
